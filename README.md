# üìú README.md - Prueba T√©cnica Desarrollador Junior

## üìù Descripci√≥n del Proyecto
Este repositorio contiene la soluci√≥n a la **Prueba T√©cnica para Desarrollador Junior en Verticcal**.  
El objetivo principal es demostrar las habilidades necesarias para el desarrollo de actividades diarias, incluyendo el desarrollo de APIs, integraci√≥n con servicios de terceros, persistencia de datos y automatizaci√≥n de flujos de trabajo.

---

## üíª Tecnolog√≠as Utilizadas
Las siguientes tecnolog√≠as fueron utilizadas en este proyecto:

- **Python 3.9+**: Con el framework FastAPI para la creaci√≥n de la API.  
- **PostgreSQL**: Base de datos para la persistencia de los leads.  
- **n8n**: Automatizaci√≥n de flujos de trabajo de procesamiento de datos, ejecutado a trav√©s de Docker en entorno local.  

---
# üõ†Ô∏è Instalaci√≥n y Ejecuci√≥n
Sigue estos pasos para configurar y ejecutar el proyecto en tu entorno local.

## 1. Configuraci√≥n del Entorno Python

**Crea un entorno virtual:**  
Abre una terminal en la ra√≠z del proyecto y ejecuta el siguiente comando:

```bash
python -m venv venv
```

**Activa el entorno virtual:**  
Es indispensable que actives el entorno virtual para instalar las dependencias en el lugar correcto.

- En Windows:  
```bash
venv\Scripts\activate
```

- En macOS/Linux:  
```bash
source venv/bin/activate
```

**Instala las dependencias:**  
Una vez activado el entorno, instala todas las librer√≠as necesarias:

```bash
pip install -r requirements.txt
```

---

## 2. Configuraci√≥n y Ejecuci√≥n de n8n con Docker

**Crea el archivo `docker-compose.yml`:**  
Verifica si tienes el archivo `docker-compose.yml` en la ra√≠z del proyecto. Si no lo tienes, usa el siguiente contenido:

```yaml
services:
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n_container
    ports:
      - '5678:5678'
    volumes:
      - ~/.n8n:/home/node/.n8n
    environment:
      - N8N_EDITOR_URL=http://localhost:5678/
    restart: unless-stopped
```

**Inicia n8n:**  
Abre una terminal en la ra√≠z del proyecto y ejecuta el siguiente comando para levantar el contenedor:

```bash
docker-compose up -d
```

**Importa y activa el flujo de trabajo:**  
- Abre tu navegador y ve a [http://localhost:5678/](http://localhost:5678/).  
- Importa el archivo `Prueba_Verticcal_n8n.json` que est√° en el proyecto.  
- Una vez importado, activa el flujo para que el webhook comience a escuchar las peticiones.  

**Configura las credenciales de PostgreSQL en n8n:**  
Para que el flujo se conecte a la base de datos, necesitas configurar las credenciales.
- En la interfaz de n8n, buscas los nodos de PostgreSQL.
- Haz clic en el campo Credential y selecciona New.
- Llena los campos con la informaci√≥n de tu base de datos (host, nombre de la base de datos, usuario y contrase√±a).
- Una vez configurado, el nodo de PostgreSQL estar√° listo para funcionar.
---

## 3. Ejecuci√≥n de la API (Backend)

**Inicia la API con FastAPI:**  
Aseg√∫rate de que tu entorno virtual est√© activo. Debes navegar a la carpeta `app` y luego ejecutar el comando de FastAPI:

```bash
cd app/
fastapi dev main.py
```

La API estar√° disponible en [http://127.0.0.1:8000](http://127.0.0.1:8000).  
Puedes ver la documentaci√≥n interactiva en [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs).  
---

## üöÄ Parte A: Manejo de APIs

### 1. Consumo de API Externa
- **API Elegida**: [JSONPlaceholder](https://jsonplaceholder.typicode.com/posts)  
- **Datos Consumidos**: Publicaciones (posts).  
- **Motivo de la elecci√≥n**: Eleg√≠ esta API para simular la interacci√≥n con datos de usuarios, lo que permiti√≥ un acercamiento pr√°ctico al an√°lisis de datos.

### 2. Endpoints de la API Propia
Se crearon los siguientes endpoints para exponer y procesar los datos de la API externa:

- `GET /external-data/posts`  
  Obtiene y devuelve una lista completa de todos los posts de la API externa.

- `GET /external-data/posts/{post_id}`  
  Recupera un post espec√≠fico utilizando su ID.

- `GET /external-data/posts/filter?field={field}&key_word={keyword}`  
  Permite filtrar los posts por una palabra clave en un campo espec√≠fico (`title` o `body`).  

### 3. Buenas Pr√°cticas Implementadas
1. **Separaci√≥n de Responsabilidades**: El proyecto est√° organizado en m√≥dulos (`routers`, `schemas`, `services`) para asegurar modularidad y f√°cil mantenimiento.  
2. **Inyecci√≥n de Dependencias**: Uso de dependencias de FastAPI para facilitar reutilizaci√≥n y pruebas unitarias.  
3. **Validaci√≥n de Datos con Pydantic**: Modelos (`PostDtoRequest`) para asegurar esquemas definidos y datos estandarizados.  
4. **Manejo de Errores**: Excepciones con respuestas HTTP apropiadas (ej. `404 Not Found`).  
5. **Patr√≥n de Abstracci√≥n**: Implementaci√≥n de `GenericUseCase` para estandarizar m√©todos y mejorar escalabilidad.  
6. **Documentaci√≥n Autom√°tica**: Endpoints documentados con FastAPI, generando Swagger UI interactivo.  

---

## üíæ Parte B: Persistencia de Leads (PostgreSQL)

Para la persistencia de datos se utiliz√≥ **PostgreSQL** con una capa de acceso a datos mediante **SQLAlchemy** en modo as√≠ncrono.

### 1. Configuraci√≥n de la Base de Datos
- **Herramienta de Persistencia**: SQLAlchemy.  
- **Esquema de la Tabla**:  
  - `id`: Identificador √∫nico (Primary Key).  
  - `name`: Nombre del lead.  
  - `location`: Ubicaci√≥n geogr√°fica.  
  - `budget`: Presupuesto asignado (`BigInteger`).  

- **Creaci√≥n de Tablas**: Script en `scripts/create_tables.py` para automatizar creaci√≥n de la base de datos y la tabla `leads`.

### 2. Ejecuci√≥n del script:
#### 1. Crear archivo .env
En la carpeta scripts, crea un archivo llamado `.env` y copia el contenido de `.env.example`. Luego, modifica la cadena de conexi√≥n de la base de datos con tus credenciales. Debes cambiar `myuser`, `mypassword` y `mydatabase` por los valores correctos:
```bash
SQLALCHEMY_DATABASE_URL=postgresql+psycopg2://myuser:mypassword@localhost:5432/mydatabase

```
### 2. Ejecuta el script:
Abre una terminal, navega hasta la carpeta del proyecto y, con el entorno virtual activado, ejecuta el comando para crear la base de datos.
```bash
cd scripts/
python -m scripts.CreateTables
```
---

## ü§ñ Parte C: Automatizaci√≥n con n8n

Se construy√≥ un flujo de trabajo en **n8n** para procesar los leads, exportado en `Prueba_Verticcal_n8n.json`.

### 1. Arquitectura del Flujo
El flujo se inicia con un **Webhook Trigger** que espera a ser llamado. A continuaci√≥n, la arquitectura de procesamiento es la siguiente:
- **Extracci√≥n de Par√°metros:** El siguiente nodo extrae los par√°metros de la URL del webhook.
- **Limpieza de Datos:** Se utiliza un nodo para eliminar toda la informaci√≥n de la base de datos, espec√≠ficamente de la tabla `leads`. 
- **Generaci√≥n de Datos de Prueba**  Un nodo de tipo `Function` retorna un JSON con nuevos valores para insertar. Esta implementaci√≥n se realiz√≥ para fines de prueba, con una posible mejora que consistir√≠a en consultar la base de datos para identificar duplicados y eliminarlos de la lista antes de la inserci√≥n.
- **Inserci√≥n en PostgreSQL:** Un nodo de PostgreSQL se encarga de insertar el array de informaci√≥n generado por el nodo anterior.
- **Recuperaci√≥n de Datos:** Un segundo nodo de PostgreSQL consulta y trae toda la informaci√≥n de la tabla `leads`.  
- **Filtrado:** La informaci√≥n se pasa a un nodo de filtrado, donde se aplican los par√°metros recibidos por el webhook (query parameters).  
- **C√°lculo y Ordenamiento:** Un nodo de tipo `Function` calcula la sumatoria de los presupuestos (`budgets`) y organiza los leads en orden descendente por presupuesto. 
- **Salidas del Flujo:** Esta √∫ltima funci√≥n se ramifica en dos salidas:
  - Una para el **Webhook Response**, que devuelve el resultado.
  - Otra para transformar el resultado en un archivo JSON, con el objetivo de permitir la descarga de la informaci√≥n, sirviendo como una base para una futura extensi√≥n del flujo.

### 2. Par√°metros Aceptados
- `location`: Filtra por ubicaci√≥n (ej. *Bogot√°*, *Medell√≠n*).  
- `budget_min`: Filtra leads con presupuesto ‚â• valor.  
- `budget_max`: Filtra leads con presupuesto ‚â§ valor.  

### 3. Ejemplo de Resultado y URL  
El flujo retorna un objeto JSON con el presupuesto total del conjunto de leads filtrados y una lista de los leads ordenados de mayor a menor presupuesto.  

**Ejemplo de URL para Postman:**  
```
http://localhost:5678/webhook/init-app?location=Medell√≠n&budget_min=200000000
```

**Ejemplo de Payload de Respuesta:**  
```json
{
  "total_budget": 1350000000,
  "sorted_leads": [
    {
      "id": 3,
      "name": "Nicolle Rodr√≠guez",
      "location": "Medell√≠n",
      "budget": "650000000"
    },
    {
      "id": 2,
      "name": "Santiago Gallo",
      "location": "Medell√≠n",
      "budget": "500000000"
    },
    {
      "id": 1,
      "name": "Ana Salcedo",
      "location": "Medell√≠n",
      "budget": "200000000"
    }
  ]
}
```

---

## ü§ñ Parte D: Meta-prompt para comunicaciones de Soporte  

Se dise√±√≥ un meta-prompt para generar mensajes de soporte t√©cnico claros, emp√°ticos y resolutivos. Este prompt gu√≠a a un modelo de lenguaje para producir comunicaciones estructuradas para los clientes en las etapas clave de una incidencia.  

Para ver el prompt completo junto con sus casos de prueba, por favor consulta el archivo `mt-promt.md`.  

### 1. Directrices del Meta-prompt  
El prompt est√° configurado para que el modelo act√∫e como un agente de soporte emp√°tico y profesional, adhiri√©ndose a las siguientes directrices:  

- **Recepci√≥n**: Confirma la recepci√≥n del caso y solicita informaci√≥n faltante de manera cort√©s.  
- **Diagn√≥stico**: Explica la causa del problema y las acciones en curso con un tono tranquilizador.  
- **Resoluci√≥n**: Detalla las acciones clave realizadas y solicita la validaci√≥n del cliente.  
- **Personalizaci√≥n y Tono**: Utiliza la informaci√≥n del cliente para personalizar el mensaje, manteniendo un tono formal, transparente y sin jerga t√©cnica.  
- **Formato**: Sigue un formato estricto de correo electr√≥nico, con un Asunto y un Cuerpo, e incluye el n√∫mero de ticket en ambas secciones.  

### 2. Raz√≥n del Meta-prompt  
Este meta-prompt se cre√≥ con el objetivo de estandarizar y mejorar la calidad de la comunicaci√≥n con los clientes, garantizando una experiencia de soporte consistente y profesional.  

Las principales razones detr√°s de su dise√±o son:  
- **Eficiencia**: Automatiza la redacci√≥n de mensajes rutinarios, liberando a los agentes de soporte para que se concentren en la resoluci√≥n de problemas m√°s complejos.  
- **Consistencia**: Asegura que todos los mensajes, independientemente del agente o del caso, sigan un formato y un tono coherentes, lo que refuerza la imagen de la marca.  
- **Empat√≠a y Transparencia**: Al establecer directrices claras para el tono y la estructura, el prompt ayuda a mantener una comunicaci√≥n emp√°tica y transparente, informando al cliente de manera oportuna sobre el estado de su caso. Esto reduce la ansiedad y aumenta la confianza en el proceso de soporte.  
- **Claridad**: Al exigir el uso de lenguaje sencillo y sin jerga t√©cnica, se garantiza que la informaci√≥n sea accesible y comprensible para todos los clientes, sin importar su nivel de conocimiento t√©cnico.  

